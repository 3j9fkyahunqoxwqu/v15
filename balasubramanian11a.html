<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">

<link rel="alternate" type="application/rss+xml" href="http://www.jmlr.org/jmlr.xml" title="JMLR RSS">
<link rel="stylesheet" type="text/css" href="../v15/balasubramanian11a_files/style.html">
<style>. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style>
<style type="text/css">
<!-- 
#fixed {
    position: absolute;
    top: 0;
    left: 0;
    width: 8em;
    height: 100%;
}
body > #fixed {
    position: fixed;
}
#content {
    margin-top: 1em;
    margin-left: 10em;
    margin-right: 0.5em;
}
img.jmlr {
    width: 7em;
}
img.rss {
    width: 2em;
}
-->
</style>
<script language="JavaScript"> 
<!-- function GoAddress(user,machine) {
document.location = 'mailto:' + user + '@' + machine; } 
// -->
</script>


</head><body>
</div>

<link rel="alternate" type="application/rss+xml" href="http://www.jmlr.org/jmlr.xml" title="JMLR RSS">
<link rel="stylesheet" type="text/css" href="../v15/balasubramanian11a_files/style.html">
<style>. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style>
<style type="text/css">
<!-- 
#fixed {
    position: absolute;
    top: 0;
    left: 0;
    width: 8em;
    height: 100%;
}
body > #fixed {
    position: fixed;
}
#content {
    margin-top: 1em;
    margin-left: 10em;
    margin-right: 0.5em;
}
img.jmlr {
    width: 7em;
}
img.rss {
    width: 2em;
}
-->
</style>
<script language="JavaScript"> 
<!-- function GoAddress(user,machine) {
document.location = 'mailto:' + user + '@' + machine; } 
// -->
</script>


<style>
. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style>

<div id="content">
<h2>Unsupervised Supervised Learning II: Margin-Based Classification without Labels</h2>
<p><i><b>Krishnakumar Balasubramanian, Pinar Donmez, Guy Lebanon</b></i>; JMLR W&amp;CP 15:137-145, 2011.
</p><h3>Abstract</h3>
Many popular linear classifiers, such as logistic regression, boosting, or SVM, are trained by optimizing margin-based risk functions. Traditionally, these risk functions are computed based on a labeled dataset. We develop a novel technique for estimating such risks using only unlabeled data and knowledge of p(y). We prove that the proposed risk estimator is consistent on high-dimensional datasets and demonstrate it on synthetic and real-world data. In particular, we show how the estimate is used for evaluating classifiers in transfer learning, and for training classifiers using exclusively unlabeled data.
<br><br>
<a target="_blank" href="../v15/balasubramanian11a/balasubramanian11a.pdf">[pdf]</a>

</div>
 <div id="fixed">
<br>
<a align="right" href="http://www.jmlr.org/" target="_top"><img class="jmlr" src="../v15/balasubramanian11a_files/jmlr.jpg" align="right" border="0"></a>
<p><br><br>
</p><p align="right"> <a href="http://www.jmlr.org/"> Home Page </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/papers"> Papers </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/author-info.html"> Submissions </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/news.html"> News </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/scope.html"> Scope </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/editorial-board.html"> Editorial Board </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/announcements.html"> Announcements </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/proceedings"> Proceedings </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/mloss">Open Source Software</a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/search-jmlr.html"> Search </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/manudb"> Login </a></p>

<br><br>
<p align="right"> <a href="http://jmlr.csail.mit.edu/jmlr.xml"> 
<img src="../v15/balasubramanian11a_files/RSS.gif" class="rss" alt="RSS Feed">
</a>
</p></div>
</body></html>
